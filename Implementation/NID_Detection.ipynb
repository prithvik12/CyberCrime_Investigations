{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import sklearn\n",
    "import io\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp_data</td>\n",
       "      <td>SF</td>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>udp</td>\n",
       "      <td>other</td>\n",
       "      <td>SF</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>S0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>neptune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>232</td>\n",
       "      <td>8153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>199</td>\n",
       "      <td>420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration protocol_type   service flag  src_bytes  dst_bytes  land  \\\n",
       "0         0           tcp  ftp_data   SF        491          0     0   \n",
       "1         0           udp     other   SF        146          0     0   \n",
       "2         0           tcp   private   S0          0          0     0   \n",
       "3         0           tcp      http   SF        232       8153     0   \n",
       "4         0           tcp      http   SF        199        420     0   \n",
       "\n",
       "   wrong_fragment  urgent  hot  ...  dst_host_srv_count  \\\n",
       "0               0       0    0  ...                  25   \n",
       "1               0       0    0  ...                   1   \n",
       "2               0       0    0  ...                  26   \n",
       "3               0       0    0  ...                 255   \n",
       "4               0       0    0  ...                 255   \n",
       "\n",
       "   dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "0                    0.17                    0.03   \n",
       "1                    0.00                    0.60   \n",
       "2                    0.10                    0.05   \n",
       "3                    1.00                    0.00   \n",
       "4                    1.00                    0.00   \n",
       "\n",
       "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "0                         0.17                         0.00   \n",
       "1                         0.88                         0.00   \n",
       "2                         0.00                         0.00   \n",
       "3                         0.03                         0.04   \n",
       "4                         0.00                         0.00   \n",
       "\n",
       "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "0                  0.00                      0.00                  0.05   \n",
       "1                  0.00                      0.00                  0.00   \n",
       "2                  1.00                      1.00                  0.00   \n",
       "3                  0.03                      0.01                  0.00   \n",
       "4                  0.00                      0.00                  0.00   \n",
       "\n",
       "   dst_host_srv_rerror_rate    label  \n",
       "0                      0.00   normal  \n",
       "1                      0.00   normal  \n",
       "2                      0.00  neptune  \n",
       "3                      0.01   normal  \n",
       "4                      0.00   normal  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"/Users/prithvikadithya/Downloads/NSL/Data\"\n",
    "train_df = pd.read_csv(path + \"/NSL_train.csv\")\n",
    "test_df  = pd.read_csv(path + \"/NSL_test.csv\")\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42,\n",
       " Index(['duration', 'protocol_type', 'service', 'flag', 'src_bytes',\n",
       "        'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot',\n",
       "        'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell',\n",
       "        'su_attempted', 'num_root', 'num_file_creations', 'num_shells',\n",
       "        'num_access_files', 'num_outbound_cmds', 'is_host_login',\n",
       "        'is_guest_login', 'count', 'srv_count', 'serror_rate',\n",
       "        'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',\n",
       "        'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count',\n",
       "        'dst_host_srv_count', 'dst_host_same_srv_rate',\n",
       "        'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
       "        'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',\n",
       "        'dst_host_srv_serror_rate', 'dst_host_rerror_rate',\n",
       "        'dst_host_srv_rerror_rate', 'label'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df.columns), train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution Training set:\n",
      "23\n",
      "label\n",
      "normal             67343\n",
      "neptune            41214\n",
      "satan               3633\n",
      "ipsweep             3599\n",
      "portsweep           2931\n",
      "smurf               2646\n",
      "nmap                1493\n",
      "back                 956\n",
      "teardrop             892\n",
      "warezclient          890\n",
      "pod                  201\n",
      "guess_passwd          53\n",
      "buffer_overflow       30\n",
      "warezmaster           20\n",
      "land                  18\n",
      "imap                  11\n",
      "rootkit               10\n",
      "loadmodule             9\n",
      "ftp_write              8\n",
      "multihop               7\n",
      "phf                    4\n",
      "perl                   3\n",
      "spy                    2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Label distribution Training set:')\n",
    "print(train_df['label'].nunique())\n",
    "print(train_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution Test set:\n",
      "label\n",
      "normal             9711\n",
      "neptune            4657\n",
      "guess_passwd       1231\n",
      "mscan               996\n",
      "warezmaster         944\n",
      "apache2             737\n",
      "satan               735\n",
      "processtable        685\n",
      "smurf               665\n",
      "back                359\n",
      "snmpguess           331\n",
      "saint               319\n",
      "mailbomb            293\n",
      "snmpgetattack       178\n",
      "portsweep           157\n",
      "ipsweep             141\n",
      "httptunnel          133\n",
      "nmap                 73\n",
      "pod                  41\n",
      "buffer_overflow      20\n",
      "multihop             18\n",
      "named                17\n",
      "ps                   15\n",
      "sendmail             14\n",
      "rootkit              13\n",
      "xterm                13\n",
      "teardrop             12\n",
      "xlock                 9\n",
      "land                  7\n",
      "xsnoop                4\n",
      "ftp_write             3\n",
      "worm                  2\n",
      "loadmodule            2\n",
      "perl                  2\n",
      "sqlattack             2\n",
      "udpstorm              2\n",
      "phf                   2\n",
      "imap                  1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Label distribution Test set:')\n",
    "print(test_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "Column 'protocol_type' has 3 categories\n",
      "Column 'service' has 70 categories\n",
      "Column 'flag' has 11 categories\n",
      "Column 'label' has 23 categories\n"
     ]
    }
   ],
   "source": [
    "### Checking the Categorical Features and their distribution\n",
    "\n",
    "print('Training set:')\n",
    "categorical_columns = train_df.select_dtypes(['object']).columns.tolist()\n",
    "for col_name in categorical_columns:\n",
    "    unique_cat = len(train_df[col_name].unique())\n",
    "    print(f\"Column '{col_name}' has {unique_cat} categories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['protocol_type', 'service', 'flag']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing the label column from the categorical columns list - because we will be grouping them down below into special categories\n",
    "categorical_columns.remove('label')\n",
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['protocol_type', 'service', 'flag']\n"
     ]
    }
   ],
   "source": [
    "## Label Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "combined_data = pd.concat([train_df, test_df], axis=0)\n",
    "# List of categorical columns\n",
    "print(categorical_columns) \n",
    "\n",
    "#Store the label encoders for inverse transforming later\n",
    "label_encoders = {} \n",
    "# Fit label encoder on combined data\n",
    "for column in categorical_columns:\n",
    "    lb = LabelEncoder()\n",
    "    lb.fit(combined_data[column])\n",
    "    label_encoders[column] = lb\n",
    "    combined_data[column] = lb.transform(combined_data[column])\n",
    "\n",
    "# Split combined data back into train and test dataframes\n",
    "train_data = combined_data[:len(train_df)]\n",
    "test_data = combined_data[len(train_df):]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labels Processing : \n",
    "The dataset was divided into separate datasets for each attack category. Attack tags have been renamed for each. 0=Normal, 1=DoS, 2=Probe, 3=R2L, 4=U2R. In new datasets, the label column is replaced with new values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_categories = { 'normal' : 0, 'neptune' : 1 ,'back': 1, 'land': 1, 'pod': 1, 'smurf': 1, 'teardrop': 1,'mailbomb': 1, 'apache2': 1, 'processtable': 1, 'udpstorm': 1, 'worm': 1,\n",
    "                           'ipsweep' : 2,'nmap' : 2,'portsweep' : 2,'satan' : 2,'mscan' : 2,'saint' : 2\n",
    "                           ,'ftp_write': 3,'guess_passwd': 3,'imap': 3,'multihop': 3,'phf': 3,'spy': 3,'warezclient': 3,'warezmaster': 3,'sendmail': 3,'named': 3,'snmpgetattack': 3,'snmpguess': 3,'xlock': 3,'xsnoop': 3,'httptunnel': 3,\n",
    "                           'buffer_overflow': 4,'loadmodule': 4,'perl': 4,'rootkit': 4,'ps': 4,'sqlattack': 4,'xterm': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_classes = {\"DoS\" : [0,1], \"Probe\" : [0,2], \"R2L\" : [0,3], \"U2R\" : [0,4]}\n",
    "train_data['label'] = train_data['label'].replace(label_categories)\n",
    "test_data['label'] = test_data['label'].replace(label_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_dfs = {\n",
    "    \"DoS\" : (train_data[train_data['label'].isin(label_classes['DoS'])], test_data[test_data['label'].isin(label_classes['DoS'])]),\n",
    "    \"Probe\" : (train_data[train_data['label'].isin(label_classes['Probe'])], test_data[test_data['label'].isin(label_classes['Probe'])]),\n",
    "    \"R2L\" : (train_data[train_data['label'].isin(label_classes['R2L'])], test_data[test_data['label'].isin(label_classes['R2L'])]),\n",
    "    \"U2R\" : (train_data[train_data['label'].isin(label_classes['U2R'])], test_data[test_data['label'].isin(label_classes['U2R'])]),\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Train, Test from Categorical labels  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_train_test_data(categorical_dfs, category : str) : \n",
    "    df = categorical_dfs[category][0]\n",
    "    X_train = df.drop('label',axis=1)\n",
    "    Y_train = df.label\n",
    "    \n",
    "    df_test = categorical_dfs[category][1]\n",
    "    X_test = df_test.drop('label',axis=1)\n",
    "    Y_test = df_test.label\n",
    "\n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Data using StandardScaler to fit the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We use StandardScaler to scale the data to zero mean and unit variance. (Basically, we are normalizing the data.)\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def train_test_transformed(categorical_dfs, category):\n",
    "\n",
    "    X_train, Y_train, X_test, Y_test = return_train_test_data(categorical_dfs, category)\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    scaler_test = preprocessing.StandardScaler().fit(X_test)\n",
    "    X_test = scaler_test.transform(X_test)\n",
    "\n",
    "    return X_train, Y_train.astype(int), X_test, Y_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use RFE to select the best features for our model from the list of columns in the dataset. Then we use the selected features to train the model.\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# We are using three classifiers here and we will select the best features from the three classifiers.\n",
    "classifiers = [SVC(kernel='linear', C=1.0, random_state=0), RandomForestClassifier(n_estimators=10,n_jobs=2), KNeighborsClassifier()]\n",
    "rfe = RFE(estimator=classifiers[1], n_features_to_select=13, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test = train_test_transformed(categorical_dfs, \"DoS\")\n",
    "#Fit the feature selector on the training data\n",
    "rfe.fit(X_train, Y_train.astype(int))\n",
    "# Transform the training data to get the selected features\n",
    "X_rfe = rfe.transform(X_train)\n",
    "\n",
    "#Get the list of columns from the categorical_dfs : \n",
    "column_Names =list(categorical_dfs[\"DoS\"][0])\n",
    "\n",
    "#Get the list of selected columns\n",
    "column_indexes =[i for i, x in enumerate(rfe.support_) if x]\n",
    "selected_column_names = [column_Names[i] for i in column_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((113270, 41), (113270, 13))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape , X_rfe.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the data on feature selector reveals only 13 columns are used to make the prediction from the 41 present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['protocol_type',\n",
       " 'service',\n",
       " 'flag',\n",
       " 'src_bytes',\n",
       " 'dst_bytes',\n",
       " 'wrong_fragment',\n",
       " 'count',\n",
       " 'srv_count',\n",
       " 'same_srv_rate',\n",
       " 'diff_srv_rate',\n",
       " 'dst_host_same_srv_rate',\n",
       " 'dst_host_serror_rate',\n",
       " 'dst_host_srv_serror_rate']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#import confusion matrix from sklearn with plot\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def run_training(categorical_dfs, category : str , classifier : int ) : \n",
    "    \n",
    "    X_train, Y_train, X_test, Y_test = train_test_transformed(categorical_dfs, category)\n",
    "\n",
    "    rfe.fit(X_train, Y_train.astype(int))\n",
    "    # Transform the training, test data to get the selected features\n",
    "    X_train_rfe = rfe.transform(X_train)\n",
    "    X_test_rfe = rfe.transform(X_test)\n",
    "\n",
    "    model = classifiers[classifier]\n",
    "    model.fit(X_train_rfe, Y_train)\n",
    "\n",
    "    Y_pred = model.predict(X_test_rfe)\n",
    "    \n",
    "    print(\"Accuracy:\",metrics.accuracy_score(Y_test, Y_pred))\n",
    "    print(\"Precision:\",metrics.precision_score(Y_test, Y_pred, average='weighted'))\n",
    "    print(\"Recall:\",metrics.recall_score(Y_test, Y_pred, average='weighted'))\n",
    "    print(\"F1:\",metrics.f1_score(Y_test, Y_pred, average='weighted'))\n",
    "\n",
    "    return pd.crosstab(Y_test, Y_pred, rownames=['Actual attacks'], colnames=['Predicted attacks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.892493157067148\n",
      "Precision: 0.8944275999247713\n",
      "Recall: 0.892493157067148\n",
      "F1: 0.8916294209779084\n",
      "Predicted attacks     0     1\n",
      "Actual attacks               \n",
      "0                  9169   542\n",
      "1                  1304  6156\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = run_training(categorical_dfs, \"DoS\", 0)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have modularized the codes, we can run this experiment for across the list of models vs category of attacks \n",
    "Model Catalog : \n",
    "\n",
    "0 = SVC \n",
    "\n",
    "1 = RandomForestClassifier\n",
    "\n",
    "2 = KNN\n",
    "\n",
    "Attack Categories : \n",
    "\n",
    "[ \"DoS\" , \"Probe\" , \"R2L\" , \"U2R\" ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.770323912353128\n",
      "Precision: 0.6708783152662976\n",
      "Recall: 0.770323912353128\n",
      "F1: 0.6721252532186955\n",
      "Predicted attacks     0   3\n",
      "Actual attacks             \n",
      "0                  9695  16\n",
      "3                  2877   8\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = run_training(categorical_dfs, \"R2L\", 0)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8967194197164523\n",
      "Precision: 0.8959498402030814\n",
      "Recall: 0.8967194197164523\n",
      "F1: 0.8870105078465449\n",
      "Predicted attacks     0     2\n",
      "Actual attacks               \n",
      "0                  9542   169\n",
      "2                  1084  1337\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix= run_training(categorical_dfs, \"Probe\", 0)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9943751278380036\n",
      "Precision: 0.994017938565049\n",
      "Recall: 0.9943751278380036\n",
      "F1: 0.9925425457534647\n",
      "Predicted attacks     0   4\n",
      "Actual attacks             \n",
      "0                  9710   1\n",
      "4                    54  13\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix= run_training(categorical_dfs, \"U2R\", 0)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8482907227301846\n",
      "Precision: 0.8763971203075219\n",
      "Recall: 0.8482907227301846\n",
      "F1: 0.8417873820448867\n",
      "Predicted attacks     0     1\n",
      "Actual attacks               \n",
      "0                  9645    66\n",
      "1                  2539  4921\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = run_training(categorical_dfs, \"DoS\", 1)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9036432575008243\n",
      "Precision: 0.8999142765267466\n",
      "Recall: 0.9036432575008243\n",
      "F1: 0.8988887958443361\n",
      "Predicted attacks     0     2\n",
      "Actual attacks               \n",
      "0                  9397   314\n",
      "2                   855  1566\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix= run_training(categorical_dfs, \"Probe\", 1)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.771117815179422\n",
      "Precision: 0.8235131890747472\n",
      "Recall: 0.771117815179422\n",
      "F1: 0.6716271985801177\n",
      "Predicted attacks     0  3\n",
      "Actual attacks            \n",
      "0                  9711  0\n",
      "3                  2883  2\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = run_training(categorical_dfs, \"R2L\", 1)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9933524238085498\n",
      "Precision: 0.9917838538576661\n",
      "Recall: 0.9933524238085498\n",
      "F1: 0.9904138937065243\n",
      "Predicted attacks     0  4\n",
      "Actual attacks            \n",
      "0                  9710  1\n",
      "4                    64  3\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix= run_training(categorical_dfs, \"U2R\", 1)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9016947178382156\n",
      "Precision: 0.9141289945624762\n",
      "Recall: 0.9016947178382156\n",
      "F1: 0.8995747513868476\n",
      "Predicted attacks     0     1\n",
      "Actual attacks               \n",
      "0                  9656    55\n",
      "1                  1633  5827\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = run_training(categorical_dfs, \"DoS\", 2)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9175733597098582\n",
      "Precision: 0.9161668450058955\n",
      "Recall: 0.9175733597098582\n",
      "F1: 0.912814519665821\n",
      "Predicted attacks     0     2\n",
      "Actual attacks               \n",
      "0                  9520   191\n",
      "2                   809  1612\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix= run_training(categorical_dfs, \"Probe\", 2)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7895363607494442\n",
      "Precision: 0.8276257572685772\n",
      "Recall: 0.7895363607494442\n",
      "F1: 0.713659256291407\n",
      "Predicted attacks     0    3\n",
      "Actual attacks              \n",
      "0                  9703    8\n",
      "3                  2643  242\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = run_training(categorical_dfs, \"R2L\", 2)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.994477398240949\n",
      "Precision: 0.9939030490089826\n",
      "Recall: 0.994477398240949\n",
      "F1: 0.9928408572048508\n",
      "Predicted attacks     0   4\n",
      "Actual attacks             \n",
      "0                  9709   2\n",
      "4                    52  15\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix= run_training(categorical_dfs, \"U2R\", 2)\n",
    "print(confusion_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
